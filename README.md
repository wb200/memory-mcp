# Memory-MCP Server

**Version**: 3.2.0  
**Status**: Production-Ready  
**License**: Open Source

A state-of-the-art memory system for AI agents using hybrid search (vector embeddings + BM25 FTS), neural reranking, and LLM-driven automated memory extraction.

---

## Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Configuration](#configuration)
- [MCP Tools](#mcp-tools)
- [Hook System](#hook-system)
- [Search Technology](#search-technology)
- [Memory Lifecycle](#memory-lifecycle)
- [Usage Examples](#usage-examples)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)
- [API Reference](#api-reference)

---

## Overview

Memory-MCP is a production-grade persistent memory system for AI coding agents (Droid, Claude Code, etc.) that automatically learns from actions and retrieves relevant insights when needed. It combines semantic vector search with keyword matching (BM25) for optimal retrieval accuracy.

### What Problems Does This Solve?

- **Lost Knowledge**: Valuable insights from debugging sessions, configurations, and patterns are forgotten
- **Context Switching**: Hard to recall what worked in previous projects
- **Duplicate Effort**: Solving the same problems repeatedly
- **Scattered Notes**: Knowledge lives in different formats across different projects

### How It Works

1. **Auto-Extraction**: A hook analyzes your agent's actions after each tool use
2. **LLM Judgment**: Gemini 3 Flash evaluates if the action is memory-worthy
3. **Intelligent Storage**: Stores insights with 1024-dimensional semantic embeddings
4. **Hybrid Retrieval**: Searches using both semantic similarity AND keyword matching
5. **Neural Reranking**: CrossEncoder re-ranks results for maximum relevance

---

## Key Features

| Feature | Description | Status |
|---------|-------------|--------|
| **7 MCP Tools** | Full CRUD operations + stats + health monitoring | âœ… Active |
| **Auto-Save Hook** | PostToolUse hook extracts memories automatically | âœ… Configured |
| **Hybrid Search** | Vector (70%) + BM25 FTS (30%) with RRF fusion | âœ… Production |
| **Neural Reranking** | CrossEncoder reranks top candidates (mxbai-reranker-base-v2, BEIR SOTA) | âœ… Active |
| **GPU Acceleration** | Ollama qwen3-embedding on RTX 5080 (or any GPU) | âœ… Supported |
| **Duplicate Prevention** | 90% similarity threshold, systematic checks | âœ… Implemented |
| **TTL Management** | 365-day expiry with hourly cleanup | âœ… Automated |
| **Fallback Chain** | Ollama â†’ Google â†’ Hash (always available) | âœ… Robust |
| **Project Scoping** | Search across all projects or project-specific | âœ… Supported |

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MEMORY-MCP v3.2.0                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   User/Agent Interaction
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Manual â”‚      â”‚  Auto-Save   â”‚
â”‚ MCP    â”‚      â”‚  Hook        â”‚
â”‚ Tools  â”‚      â”‚  (PostToolUse)â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚ LLM Judge (Gemini    â”‚
    â”‚    â”‚ 3 Flash Preview)     â”‚
    â”‚    â”‚ Determines:          â”‚
    â”‚    â”‚ - Worthiness?        â”‚
    â”‚    â”‚ - Category (8 types) â”‚
    â”‚    â”‚ - Content format     â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚ Embedding Generation â”‚
    â”‚    â”‚ - Primary: Ollama    â”‚
    â”‚    â”‚   qwen3-embedding    â”‚
    â”‚    â”‚   (1024-dim, GPU)    â”‚
    â”‚    â”‚ - Fallback: Google   â”‚
    â”‚    â”‚ - Last: Hash-based   â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚ Duplicate Check      â”‚
    â”‚    â”‚ (90% similarity)     â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚    LanceDB          â”‚
           â”‚  - 1024-dim vectors  â”‚
           â”‚  - BM25 FTS index   â”‚
           â”‚  - Project scoping  â”‚
           â”‚  - TTL (365 days)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚  Query Processing   â”‚
           â”‚                     â”‚
           â”‚  1. Vector Search   â”‚
           â”‚     (cosine sim)    â”‚
           â”‚                     â”‚
           â”‚  2. FTS Search      â”‚
           â”‚     (BM25 Keywords) â”‚
           â”‚                     â”‚
           â”‚  3. RRF Fusion      â”‚
           â”‚     (70% + 30%)     â”‚
           â”‚                     â”‚
           â”‚  4. Neural Rerank   â”‚
           â”‚     (CrossEncoder)  â”‚
           â”‚                     â”‚
           â”‚  5. TTL Filter      â”‚
           â”‚                     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation

### Prerequisites

- Python 3.11 or higher
- Ollama (optional, for local embeddings) OR Google API key
- GPU optional (but recommended for performance)

### Step 1: Clone and Setup

```bash
# Clone the repository
git clone <repo-url>
cd memory-mcp

# Create virtual environment and install dependencies
uv sync

# Activate virtual environment (or use uv run for commands)
source .venv/bin/activate  # On Linux/Mac
# or
.venv\Scripts\activate  # On Windows
```

### Step 2: Install Ollama (Recommended)

For best performance and privacy, use Ollama for local embeddings:

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull the qwen3-embedding model
ollama pull qwen3-embedding:0.6b

# Start Ollama server
ollama serve
```

**GPU Acceleration (Optional)**:

If you have a GPU, create a systemd service:

```ini
# /etc/systemd/system/ollama.service
[Unit]
Description=Ollama Local LLM Service
After=network-online.target
Wants=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
Environment="CUDA_VISIBLE_DEVICES=0"
Environment="OLLAMA_NUM_GPU=all"
Nice=-5
MemoryMax=8G
CPUQuota=200%
LimitNOFILE=65536
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
sudo systemctl daemon-reload
sudo systemctl enable ollama
sudo systemctl start ollama
```

### Step 3: Configure MCP Client

Add to your MCP configuration (usually `~/.config/claude/mcp.json` or `~/.factory/mcp.json`):

```json
{
  "mcpServers": {
    "droid-memory": {
      "command": "/path/to/memory-mcp/.venv/bin/python",
      "args": ["/path/to/memory-mcp/server.py"],
      "env": {
        "EMBEDDING_PROVIDER": "ollama",
        "EMBEDDING_MODEL": "qwen3-embedding:0.6b",
        "EMBEDDING_DIM": "1024",
        "OLLAMA_BASE_URL": "http://localhost:11434",
        "GOOGLE_API_KEY": "your-google-api-key",  # Optional fallback
        "DROID_MEMORY_DB_PATH": "~/.factory/lancedb-memory"
      }
    }
  }
}
```

### Step 4: Configure Auto-Save Hook (Optional)

Add to your agent settings (`~/.factory/settings.json` or equivalent):

```json
{
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Edit|Write|Bash|MultiEdit",
        "hooks": [
          {
            "type": "command",
            "command": "/path/to/.factory/hooks/memory-extractor.py",
            "timeout": 30
          }
        ]
      }
    ]
  }
}
```

---

## Configuration

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `EMBEDDING_PROVIDER` | `ollama` | `ollama` or `google` |
| `EMBEDDING_MODEL` | `qwen3-embedding:0.6b` | Model name for embeddings |
| `EMBEDDING_DIM` | `1024` | Embedding dimension |
| `OLLAMA_BASE_URL` | `http://localhost:11434` | Ollama API endpoint |
| `GOOGLE_API_KEY` | - | Google Gemini API key (fallback) |
| `DROID_MEMORY_DB_PATH` | `~/.factory/lancedb-memory` | Database location |

### Code Configuration (Config Class)

| Setting | Default | Description |
|---------|---------|-------------|
| `llm_model` | `gemini-3-flash-preview` | LLM judge for auto-save |
| `ttl_days` | `365` | Memory time-to-live |
| `dedup_threshold` | `0.90` | Duplicate similarity threshold |
| `fts_weight` | `0.3` | FTS weight in RRF fusion |
| `rate_limit_seconds` | `30` | Auto-save rate limit |

---

## MCP Tools

### Available Tools

| Tool | Description | Read-Only | Destructive | Idempotent |
|------|-------------|-----------|-------------|------------|
| `memory_save` | Save a memory with semantic embedding | No | No | No |
| `memory_recall` | Search across ALL projects | Yes | No | Yes |
| `memory_recall_project` | Search in CURRENT project only | Yes | No | Yes |
| `memory_delete` | Delete a memory by ID | No | Yes | Yes |
| `memory_update` | Update an existing memory | No | No | Yes |
| `memory_stats` | Get statistics by category/project | Yes | No | Yes |
| `memory_health` | Get system health status | Yes | No | Yes |

### Tool Details

#### memory_save

Save a manually crafted memory.

```python
memory_save(
    content="[CONFIG] - Astral uv requires Python 3.11+. Context: Setup. Rationale: Hard requirement documented.",
    category="CONFIG",
    tags=["uv", "python", "setup"],
    summarize=False  # Optional: let LLM summarize
)
```

**Response**:
```
Saved (ID: a1b2c3d4..., CONFIG)
Tags: ['uv', 'python', 'setup']
```

#### memory_recall

Search across all projects.

```python
memory_recall(
    query="uv python version requirements",
    limit=5,
    category=None  # Optional: filter by category
)
```

**Response**:
```
Found 3 memories:

[1] CONFIG - Astral uv requires Python 3.11+. Context: Setup project. Rationale: Hard requirement.
    ID: a1b2c3d4...
    Category: CONFIG
    Tags: ['uv', 'python', 'setup']
    Similarity: 94%
    Search: hybrid (vector + BM25 RRF)

[2] PREF - User prefers uv over pip for package management. Context: All projects.
    ID: e5f6g7h8...
    Category: PREF
    Tags: ['uv', 'preference']
    Similarity: 87%
```

#### memory_recall_project

Search within current project only.

```python
memory_recall_project(
    query="project-specific pattern",
    limit=5,
    category=None
)
```

#### memory_delete

Delete a memory by ID (full ID or partial prefix).

```python
memory_delete(memory_id="a1b2c3d4")
# or partial match
memory_delete(memory_id="a1b2")
```

#### memory_update

Update an existing memory.

```python
memory_update(
    memory_id="a1b2c3d4",
    content="[CONFIG] - Updated: Astral uv requires Python 3.11+. Context: Setup. Rationale: Verified with documentation.",
    category="CONFIG",
    tags=["uv", "python", "setup", "verified"]
)
```

#### memory_stats

Get memory statistics.

```python
memory_stats()
```

**Response**:
```
Total Memories: 4

By Category:
- CONFIG: 2
- PREF: 1
- PATTERN: 1

By Project:
- /home/user/project-a: 2
- /home/user/project-b: 2
```

#### memory_health

Get system health status.

```python
memory_health()
```

**Response**:
```
Memory Health Status âœ“

Database: ~/.factory/lancedb-memory
Total Memories: 4
Vector Dimensions: 1024
FTS Index: Enabled (Tantivy)
GPU Available: Yes (RTX 5080)
Config: embedding_provider=ollama, dedup_threshold=0.90
```

---

## Hook System

### What is the Hook?

The `memory-extractor.py` hook runs automatically after each tool use (Edit, Write, Bash, etc.) and:

1. **Captures** the tool name, input, output, and recent context
2. **Judges** whether the action is memory-worthy using LLM
3. **Extracts** category, content, and tags if worthy
4. **Checks** for duplicates (90% similarity)
5. **Saves** the memory automatically

### LLM Judge Criteria

The LLM judge (Gemini 3 Flash Preview) saves memories ONLY if they match:

- Bug fix with non-obvious cause/solution
- New coding pattern or architecture insight
- Configuration that took effort to get right
- Error resolution with reusable fix
- Performance optimization technique
- User preference explicitly stated

It SKIPS:
- Simple file reads or directory listings
- Trivial edits or formatting changes
- Commands that just check status
- Actions without learning value

### Memory Categories

The system uses 8 standardized categories:

| Category | When to Use |
|----------|-------------|
| `PATTERN` | Coding patterns, architectures, design decisions |
| `CONFIG` | Tool configurations, environment settings, setup instructions |
| `DEBUG` | Error resolutions, debugging techniques, bug fixes |
| `PERF` | Performance optimizations, resource management |
| `PREF` | User preferences, coding style choices |
| `INSIGHT` | Cross-project learnings, general observations |
| `API` | LLM/external API usage patterns |
| `AGENT` | Agent design patterns, workflows |

### Hook Limits

- **Rate Limit**: 30 seconds between extractions
- **Timeout**: 30 seconds per hook execution
- **Context**: Reads last 5 messages from transcript

---

## Search Technology

### Hybrid Search Architecture

Memory-MCP uses **true hybrid search** combining:

1. **Vector Search** (70% weight)
   - 1024-dimensional semantic embeddings
   - Cosine similarity
   - Captures meaning, not just keywords

2. **BM25 FTS** (30% weight)
   - Tantivy-based full-text search
   - Keyword matching with TF-IDF weighting
   - Catches exact phrases and rare terms

3. **RRF Fusion**
   - Reciprocal Rank Fusion combines both results
   - Weighted by search quality
   - Prevents either method from dominating

4. **Neural Reranking**
   - CrossEncoder re-ranks top 50 candidates
   - Model: `mixedbread-ai/mxbai-reranker-base-v2` (BEIR SOTA, RL-trained)
   - Query-document pairwise scoring
   - Improves final relevance by 10-15%

### Search Flow

```
Query â†’ Embedding (1024-dim)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector Search           â”‚ â† Fetch top 50 (cosine)
â”‚ (cosine similarity)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FTS Search              â”‚ â† Fetch top 50 (BM25)
â”‚ (keyword matching)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RRF Fusion             â”‚ â† Combine 70/30
â”‚ 1/(k + rank) weighted  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neural Reranking       â”‚ â† CrossEncoder
â”‚ mxbai-reranker-base-v2  â”‚   (BEIR SOTA, RL)
â”‚ Query-document scoring  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TTL Filter             â”‚ â† Remove expired
â”‚ expires_at > NOW       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
        Top K Results
```

### Performance

| Operation | Time | Notes |
|-----------|------|-------|
| Embedding Generation | 10-50ms | GPU: ~10ms, CPU: ~30-50ms |
| Vector Search | 20-30ms | HNSW index when available |
| FTS Search | 2-5ms | Tantivy BM25 |
| RRF Fusion | <1ms | O(n) where n = 100 |
| Neural Reranking | 20-50ms | CrossEncoder (mxbai-reranker-base-v2) on top 50 |
| **Total Recall** | **50-130ms** | Full hybrid search |

---

## Memory Lifecycle

### Complete Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CREATION PHASE                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Source: Manual MCP Call OR Auto-Save Hook
  â†“
LLM Judge Determines Worthiness
  â†“
Embedding Generation (Ollama â†’ Google â†’ Hash)
  â†“
Duplicate Check (90% similarity threshold)
  â†“ Duplicate â†’ Skip, not memory-worthy
  â†“ Unique â†’ Continue
  â†“
Store to LanceDB
  - id: UUID
  - vector: 1024-dim
  - category: 8 valid types
  - content, tags, project_id
  - created_at, updated_at
  - expires_at: NOW + 365 days
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ACTIVE PHASE                               â”‚
â”‚ Available for recall (TTL checked on each query)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RETRIEVAL PHASE                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query Input
  â†“
Vector Search + FTS Search
  â†“
RRF Fusion (70% + 30%)
  â†“
Neural Reranking
  â†“
TTL Filter
  â†“
Return Top K Results

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    UPDATE PHASE                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

memory_update(memory_id, ...)
  â†“
Create NEW row (re-embed, updated timestamp)
  â†“
Delete OLD row (race-safe filter)
  â†“
Memory UPDATED

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXPIRATION PHASE                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Background Cleanup Task (every 24 hours)
  â†“
DELETE WHERE expires_at < NOW
  â†“
Memory EXPIRED (not retrievable)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DELETION PHASE                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

memory_delete(memory_id)
  â†“
Delete row from LanceDB
  â†“
Memory DELETED
```

### TTL Management

| TTL Aspect | Configuration |
|------------|---------------|
| Default TTL | 365 days |
| Cleanup Interval | Every 24 hours |
| Query Filtering | Excluded from recall if expired |
| Configuration | `ttl_days` in Config class |

---

## Usage Examples

### Example 1: Manual Memory Save

```python
# After fixing a tricky PyTorch CUDA error
memory_save(
    content="[DEBUG] - 'RuntimeError: CUDA out of memory' solved with gradient_checkpointing=True. Context: Fine-tuning transformer on RTX 4090. Rationale: Gradient checkpointing trades compute for memory.",
    category="DEBUG",
    tags=["pytorch", "cuda", "memory", "training"]
)
```

### Example 2: Recall Similar Problem

```python
# When hitting CUDA error again
memories = memory_recall(
    query="CUDA out of memory pytorch training",
    limit=3,
    category="DEBUG"
)

# Result: Returns the gradient checkpointing solution
```

### Example 3: Auto-Save via Hook

No manual action required! After running a command:

```bash
# You run this command
pip install --upgrade ruff

# Hook automatically runs and saves:
# "PATTERN - Always use uv for Python package management, not pip. Context: Project setup. Rationale: uv is faster and more reliable."
```

### Example 4: Project-Specific Memory

```python
# Save project-specific configuration
memory_save(
    content="[CONFIG] - This project uses Eslint with Prettier integration. Context: frontend project. Rationale: Consistent code formatting.",
    category="CONFIG",
    tags=["eslint", "prettier", "frontend"]
)

# Later, recall in this project only
memories = memory_recall_project(
    query="formatter configuration",
    limit=5
)
```

### Example 5: Check System Health

```python
health = memory_health()
print(health)

# Output:
# Memory Health Status âœ“
# Database: ~/.factory/lancedb-memory
# Total Memories: 47
# Vector Dimensions: 1024
# FTS Index: Enabled (Tantivy)
```

---

## Testing

### Run All Tests

```bash
cd memory-mcp
uv run pytest -v
```

### Test Results (Current)

```
============================= test session starts ==============================
platform linux -- Python 3.12.12, pytest-9.0.2
collected 30 items

test_server.py::TestMemorySave::test_save_basic PASSED                [  3%]
test_server.py::TestMemorySave::test_save_empty_content_fails PASSED  [  6%]
test_server.py::TestMemorySave::test_save_all_valid_categories PASSED [ 20%]
test_server.py::TestMemorySave::test_deduplication_detection PASSED   [ 23%]
test_server.py::TestMemoryRecall::test_recall_semantic PASSED         [ 26%]
test_server.py::TestMemoryRecall::test_recall_shows_hybrid_search PASSED [ 40%]
test_server.py::TestMemoryRecall::test_project_scoped_search PASSED   [ 43%]
test_server.py::TestMemoryUpdate::test_update_content PASSED          [ 46%]
test_server.py::TestMemoryDelete::test_delete_existing PASSED         [ 60%]
test_server.py::TestMemoryStats::test_stats_structure PASSED          [ 66%]
test_server.py::TestEmbeddings::test_embedding_generation PASSED       [ 70%]
test_server.py::TestConcurrency::test_concurrent_saves PASSED         [ 80%]
test_server.py::TestConcurrency::test_concurrent_mixed_operations PASSED [ 83%]
test_server.py::TestFullLifecycle::test_create_read_update_delete PASSED [ 90%]
test_server.py::TestHookIntegration::test_hook_exists PASSED         [ 93%]
test_server.py::TestMCPConfig::test_mcp_config_valid PASSED          [100%]

============================= 30 passed in 25.10s ==============================
```

### Test Coverage

| Test Suite | Tests | Coverage |
|------------|-------|----------|
| `TestMemorySave` | 7 tests | Save validation, deduplication |
| `TestMemoryRecall` | 6 tests | Search, filtering, project scope |
| `TestMemoryUpdate` | 3 tests | Update operations, validation |
| `TestMemoryDelete` | 3 tests | Delete by ID, partial match |
| `TestMemoryStats` | 1 test | Statistics accuracy |
| `TestEmbeddings` | 2 tests | Embedding generation, similarity |
| `TestSummarization` | 1 test | LLM summarization |
| `TestConcurrency` | 3 tests | Thread safety, race conditions |
| `TestFullLifecycle` | 1 test | End-to-end CRUD flow |
| `TestHookIntegration` | 2 tests | Hook configuration, syntax |
| `TestMCPConfig` | 1 test | MCP config validation |

---

## Troubleshooting

### Common Issues

#### Issue 1: "GOOGLE_API_KEY not found"

**Cause**: No Google API key configured for LLM judge or fallback embeddings.

**Solution**:
```bash
export GOOGLE_API_KEY="your-api-key-here"
# or add to ~/.bashrc
echo 'export GOOGLE_API_KEY="your-api-key"' >> ~/.bashrc
```

#### Issue 2: "Ollama connection refused"

**Cause**: Ollama server not running.

**Solution**:
```bash
# Start Ollama
ollama serve

# Or check systemd status
sudo systemctl status ollama
sudo systemctl start ollama
```

#### Issue 3: "Duplicate detected" too frequently

**Cause**: `dedup_threshold` is too strict.

**Solution**: Lower the threshold in `server.py` and `memory-extractor.py`:
```python
dedup_threshold: float = 0.85  # Try 85% instead of 90%
```

#### Issue 4: Hook not triggering

**Cause**: Hook not configured in settings.json or permissions wrong.

**Solution**:
1. Check hook configuration in `~/.factory/settings.json`
2. Make hook executable:
```bash
chmod +x ~/.factory/hooks/memory-extractor.py
```
3. Check hook logs:
```bash
tail -f ~/.factory/logs/memory-extractor.log
```

#### Issue 5: Embedding dimension mismatch

**Cause**: Changed embedding model but database still uses old dimensions.

**Solution**: Reset database:
```bash
rm -rf ~/.factory/lancedb-memory
# Database will be recreated on next save
```

### Debug Mode

Enable verbose logging:

```python
# In server.py, add at top:
import logging
logging.basicConfig(level=logging.DEBUG)
```

### Health Check

Always check system health first when issues arise:

```python
memory_health()
```

---

## API Reference

### Memory Schema

```python
@dataclass
class Memory:
    id: str              # UUID
    content: str         # Memory text (indexed for FTS)
    vector: Vector(1024) # 1024-dimensional embedding
    category: str        # PATTERN|CONFIG|DEBUG|PERF|PREF|INSIGHT|API|AGENT
    tags: str           # JSON array string: '["tag1", "tag2"]'
    project_id: str     # Git remote URL or cwd
    user_id: str | None # Optional user identifier
    created_at: str     # ISO timestamp
    updated_at: str     # ISO timestamp
    expires_at: str | None  # ISO timestamp (TTL)
```

### Config Schema

```python
@dataclass(frozen=True, slots=True)
class Config:
    db_path: Path = Path.home() / ".factory" / "lancedb-memory"
    table_name: str = "memories"
    embedding_model: str = "qwen3-embedding:0.6b"
    embedding_dim: int = 1024
    embedding_provider: str = "ollama"  # ollama | google
    ollama_base_url: str = "http://localhost:11434"
    llm_model: str = "gemini-3-flash-preview"
    ttl_days: int = 365
    dedup_threshold: float = 0.90
    rate_limit_seconds: int = 30
    fts_weight: float = 0.3  # 30% FTS in RRF
    default_limit: int = 5
    max_limit: int = 50
```

---

## Production Deployment

### Scaling Considerations

| Aspect | Current | Production Recommendation |
|--------|---------|---------------------------|
| Storage | Local file | Postgres + pgvector OR Pinecone |
| Indexing | Auto-create | Pre-build IVF-PQ at 1k+ memories |
| Cleanup | Background task | Separate cron job |
| Monitoring | `memory_health()` | Prometheus metrics |
| Backup | None | Daily DB snapshots |

### High Availability

```python
# Use environment overrides for HA
os.environ["DROID_MEMORY_DB_PATH"] = "/mnt/shared/lancedb-memory"
os.environ["EMBEDDING_PROVIDER"] = "ollama"
os.environ["OLLAMA_BASE_URL"] = "http://ollama-cluster:11434"
```

### Backup Strategy

```bash
# Daily backup cron job
0 2 * * * rsync -av ~/.factory/lancedb-memory/ /backup/lancedb-memory-$(date +\%Y\%m\%d)/
```

---

## FAQ

### Q: Does the MCP server work?
**A**: âœ… YES - All 7 MCP tools are functional and tested.

### Q: How many MCP tools are available?
**A**: 7 tools: `memory_save`, `memory_recall`, `memory_recall_project`, `memory_delete`, `memory_update`, `memory_stats`, `memory_health`.

### Q: Are hooks available and working?
**A**: âœ… YES - The `memory-extractor.py` hook is configured in `~/.factory/settings.json` and actively auto-saves memories after Edit, Write, Bash, and MultiEdit tool uses.

### Q: Is LanceDB working?
**A**: âœ… YES - Database located at `~/.factory/lancedb-memory` with 1024-dimensional vectors and BM25 FTS index.

### Q: Is BM25 FTS hybrid search enabled?
**A**: âœ… CONFIRMED - Tantivy-based BM25 is active with Reciprocal Rank Fusion (RRF) combining vector (70%) and FTS (30%) results.

### Q: What is the memory life cycle?
**A**: CREATE â†’ ACTIVE (365 days TTL) â†’ EXPIRED â†’ DELETED (automatic cleanup every 24 hours).

### Q: What governs memory lifecycle?
**A**: Configuration-based (`ttl_days`, `dedup_threshold`, LLM judge prompt) - no user prompt needed during operation.

### Q: Which LLM is used for the judge?
**A**: Google Gemini 3 Flash Preview (via `gemini-3-flash-preview` model).

### Q: How is duplicate prevention handled?
**A**: 90% cosine similarity threshold with systematic pre-save checks in BOTH the hook and `memory_save()` function.

### Q: Is GPU acceleration supported?
**A**: âœ… YES - Ollama qwen3-embedding runs on GPU (e.g., RTX 5080 with 1500 MiB VRAM).

### Q: Can I use this without Ollama?
**A**: Yes, set `EMBEDDING_PROVIDER=google` and provide a `GOOGLE_API_KEY`. Ollama is recommended for privacy and performance.

### Q: What CrossEncoder model is used for re-ranking?
**A**: `mixedbread-ai/mxbai-reranker-base-v2` - a state-of-the-art BERT model trained with reinforcement learning, leading the BEIR benchmark. It's loaded automatically by LanceDB's `CrossEncoderReranker` class with 0.5B parameters, providing excellent accuracy with manageable memory footprint (~200MB).

### Q: What happens if embeddings fail?
**A**: Fallback chain: Ollama â†’ Google â†’ deterministic hash-based embeddings. Guarantees system always works.

---

## Contributing

Contributions welcome! Please ensure:

1. All tests pass: `uv run pytest -v`
2. Code formatted: `uv run ruff format .`
3. Linter passes: `uv run ruff check .`
4. New features include tests

---

## License

Open Source - See LICENSE file for details.

---

## Acknowledgments

- **LanceDB**: Vector database backend
- **Tantivy**: Full-text search with BM25
- **Sentence-Transformers**: CrossEncoder neural reranking (`mixedbread-ai/mxbai-reranker-base-v2`)
- **Ollama**: Local embedding generation
- **Google Gemini**: LLM judge
- **MCP**: Model Context Protocol

---

## Contact & Support

- Issues: GitHub Issues
- Documentation: See `/docs` directory
- Release Notes: See CHANGELOG.md

---

**Version History**:
- **v3.2.0** - Upgraded to SOTA reranker (mxbai-reranker-base-v2, BEIR leader)
- **v3.1.0** - Tantivy FTS, reranker fix, embedding cache, TTL cleanup
- **v3.0.0** - Ollama integration, 1024-dim embeddings, GPU support
- **v2.0.0** - Hook system, LLM judge, auto-save
- **v1.0.0** - Initial release with LanceDB and vector search

---

**Ready for Production! ğŸš€**
